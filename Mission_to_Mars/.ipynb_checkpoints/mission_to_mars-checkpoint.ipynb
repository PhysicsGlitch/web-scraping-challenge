{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pymongo\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from splinter import Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define my home page urls for the four sites here. Some will be modified but some can be used directly. \n",
    "\n",
    "nasa_url = 'https://mars.nasa.gov/news/8744/nasa-engineers-checking-insights-weather-sensors/'\n",
    "mars_facts_url = 'https://space-facts.com/mars/'\n",
    "astro_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "jpl_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Soup Scrape for Title and Paragraph - Nasa Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created a soup scrape function to scrape and convert the html.\n",
    "def soup_scrape(url, db_name):\n",
    "    response = requests.get(url)\n",
    "    return(bs(response.text, 'lxml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first scrape is for the Nasa homepage to get the latest title and content. \n",
    "\n",
    "nasa_scrape = soup_scrape(nasa_url, 'nasa_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "An electronics issue is suspected to be preventing the sensors from sharing their data about Mars weather with the spacecraft.\n",
      "On Sept. 6, 2020, InSight's weather sensors (collectively called the Auxiliary Payload Sensor Suite, or APSS) were reset. They appear to be operating nominally again, gathering data on wind speed and direction, air temperature and pressure, and magnetic fields. Although the issue that required APSS to be reset has not been determined, the team will continue to carefully monitor the situation.\n"
     ]
    }
   ],
   "source": [
    "# I saved my title and paragraphs texts below\n",
    "\n",
    "nasa_title = nasa_scrape.title.text\n",
    "\n",
    "# I noticed that the \"intro\" paragraph was marked with an <i> tag. And the homework example just included the <i>. So instead of pulling all the <p> elements, I just grapped the <i> elements to put into my scrape.\n",
    "# To get the text from these elements I needed to use the getText method on each individual element. However, getText is not compatible with find_all(), only fin() so I made a loop and then created my text list. \n",
    "#That filtered out the html <> elements without me needing to manually do that.\n",
    "\n",
    "\n",
    "for string in nasa_scrape.find_all('i'):\n",
    "    nasa_paragraph = \"\"\n",
    "    nasa_paragraph += string.getText()\n",
    "    print (nasa_paragraph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splinter Scrape for Images - JPL Mars Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For splinter I installed chromedriver in the same file as the python nb. I need to define the executable path to chromedriver and then give it the link. This sets up the browser visit.\n",
    "# The next cell of text then conducts the scrape for the images. \n",
    "\n",
    "executable_path = {\"executable_path\": 'chromedriver.exe'}\n",
    "jpl_browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the url and browser visit.\n",
    "url = jpl_url\n",
    "jpl_browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"carousel_items\">\n",
      "<article alt=\"Sun Shines in High-Energy X-rays\" class=\"carousel_item\" style=\"background-image: url('/spaceimages/images/wallpaper/PIA18906-1920x1200.jpg');\">\n",
      "<div class=\"default floating_text_area ms-layer\">\n",
      "<h2 class=\"category_title\">\n",
      "</h2>\n",
      "<h2 class=\"brand_title\">\n",
      "\t\t\t\t  FEATURED IMAGE\n",
      "\t\t\t\t</h2>\n",
      "<h1 class=\"media_feature_title\">\n",
      "\t\t\t\t  Sun Shines in High-Energy X-rays\t\t\t\t</h1>\n",
      "<div class=\"description\">\n",
      "</div>\n",
      "<footer>\n",
      "<a class=\"button fancybox\" data-description=\"X-rays stream off the sun in this first picture of the sun, overlaid on a picture taken by NASA's Solar Dynamics Observatory, taken by NuSTAR.\" data-fancybox-group=\"images\" data-fancybox-href=\"/spaceimages/images/mediumsize/PIA18906_ip.jpg\" data-link=\"/spaceimages/details.php?id=PIA18906\" data-title=\"Sun Shines in High-Energy X-rays\" id=\"full_image\">\n",
      "\t\t\t\t\tFULL IMAGE\n",
      "\t\t\t\t  </a>\n",
      "</footer>\n",
      "</div>\n",
      "<div class=\"gradient_container_top\"></div>\n",
      "<div class=\"gradient_container_bottom\"></div>\n",
      "</article>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# This proved to be the hardest scrape. I found that the full image was in the wall paper text and on a carousel rotating list. I could use beautiful soup to find the carousel_html where the image path was stored. But the url was\n",
    "# not easily extractable because it wasn't directly tied to a tag. There may be a better way to do this, but I was able to use regex to extract the necessary url. I basically converted where\n",
    "# I found the carousel_html into a string and then did a regex pattern search on that html code to extract the wallpaper/full image path\n",
    "\n",
    "html = jpl_browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "carousel_html = soup.find('div', 'carousel_items', 'style')\n",
    "carousel_string = str(carousel_html)\n",
    "\n",
    "# Close the browser after scraping\n",
    "jpl_browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/images/wallpaper/PIA18906-1920x1200\n"
     ]
    }
   ],
   "source": [
    "#pattern = \"url('(.*?)');\"\n",
    "search_pattern = \"(?<=spaceimages).*?(?=.jpg)\"\n",
    "url_img = re.search(search_pattern, carousel_string).group(0)\n",
    "print(url_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA18906-1920x1200.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_image_path = '/spaceimages/images/wallpaper/PIA08097-1920x1200.jpg'\n",
    "mars_image = \"https://www.jpl.nasa.gov\" + \"/spaceimages\" + url_img + \".jpg\"\n",
    "mars_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pandas Scrape for Tabular Data - Mars Facts Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Fact': 'Equatorial Diameter:', 'Value': '6,792 km'},\n",
       " {'Fact': 'Polar Diameter:', 'Value': '6,752 km'},\n",
       " {'Fact': 'Mass:', 'Value': '6.39 × 10^23 kg (0.11 Earths)'},\n",
       " {'Fact': 'Moons:', 'Value': '2 (Phobos & Deimos)'},\n",
       " {'Fact': 'Orbit Distance:', 'Value': '227,943,824 km (1.38 AU)'},\n",
       " {'Fact': 'Orbit Period:', 'Value': '687 days (1.9 years)'},\n",
       " {'Fact': 'Surface Temperature:', 'Value': '-87 to -5 °C'},\n",
       " {'Fact': 'First Record:', 'Value': '2nd millennium BC'},\n",
       " {'Fact': 'Recorded By:', 'Value': 'Egyptian astronomers'}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Mars facts table is probably the easiest scrape as we can just use Pandas to read the html and extract the tabular data which we shall save in mars_table\n",
    "# I found the Pandas to_html to be very easy to work with. So what I did was a read the html in Pandas. Then I converted the list it pulled into a Pandas table. \n",
    "# I then took the tabular data I needed and converted it to a record dictionary so I could pull the elements into my index.html file.\n",
    "# I know a more sophisticated way I could do this would be to convert the table back to html and then upload the html directly. I looked at some jquery ways to do it\n",
    "# but decided to just do it manually because I needed to finish this assignment. \n",
    "\n",
    "mars_table = pd.read_html(mars_facts_url)\n",
    "mars_facts = pd.DataFrame(mars_table[0])\n",
    "mars_facts.columns=[\"Fact\", \"Value\"]\n",
    "mars_facts.set_index([\"Fact\"])\n",
    "mars_facts_dict = mars_facts.to_dict('record')\n",
    "mars_facts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemisphere Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The final task is also fairly straight forward. I just needed to find where the hemisphere image urls were stored and then create a dictionary so they could be added to my final index.html template.\n",
    "cerberus_url = 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'\n",
    "schiaparelli_url = 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'\n",
    "syrtis_major_url = 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'\n",
    "valles_marineris_url = 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'\n",
    "\n",
    "mars_hemi_images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cerberus': {'title': 'Cerberus',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
       " 'syrtis_mjr': {'title': 'Syrtis Major',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
       " 'vales_marineris': {'title': 'Valles Marineris',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'},\n",
       " 'schiaparelli': {'title': 'Schiaparelli',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cerberus = {'title': 'Cerberus', 'img_url': cerberus_url}\n",
    "syrtis_mjr = {'title': 'Syrtis Major', 'img_url': syrtis_major_url}\n",
    "vales_marineris = {'title': 'Valles Marineris', 'img_url': valles_marineris_url}\n",
    "schiaparelli = {'title': 'Schiaparelli', 'img_url': schiaparelli_url}\n",
    "mars_hemi_images['cerberus'] = cerberus\n",
    "mars_hemi_images['syrtis_mjr'] = syrtis_mjr\n",
    "mars_hemi_images['vales_marineris'] = vales_marineris\n",
    "mars_hemi_images['schiaparelli'] = schiaparelli\n",
    "mars_hemi_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cerberus': {'title': 'Cerberus', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, 'syrtis_mjr': {'title': 'Syrtis Major', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, 'vales_marineris': {'title': 'Valles Marineris', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}, 'schiaparelli': {'title': 'Schiaparelli', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}}\n"
     ]
    }
   ],
   "source": [
    "print(mars_hemi_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_hemi_images['cerberus']['img_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cerberus': {'title': 'Cerberus',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
       " 'syrtis_mjr': {'title': 'Syrtis Major',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
       " 'vales_marineris': {'title': 'Valles Marineris',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'},\n",
       " 'schiaparelli': {'title': 'Schiaparelli',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
       " 'mars_facts_dict': [{'Fact': 'Equatorial Diameter:', 'Value': '6,792 km'},\n",
       "  {'Fact': 'Polar Diameter:', 'Value': '6,752 km'},\n",
       "  {'Fact': 'Mass:', 'Value': '6.39 × 10^23 kg (0.11 Earths)'},\n",
       "  {'Fact': 'Moons:', 'Value': '2 (Phobos & Deimos)'},\n",
       "  {'Fact': 'Orbit Distance:', 'Value': '227,943,824 km (1.38 AU)'},\n",
       "  {'Fact': 'Orbit Period:', 'Value': '687 days (1.9 years)'},\n",
       "  {'Fact': 'Surface Temperature:', 'Value': '-87 to -5 °C'},\n",
       "  {'Fact': 'First Record:', 'Value': '2nd millennium BC'},\n",
       "  {'Fact': 'Recorded By:', 'Value': 'Egyptian astronomers'}],\n",
       " 'nasa_title': \"NASA Engineers Checking InSight's Weather Sensors – NASA’s Mars Exploration Program \",\n",
       " 'nasa_paragraph': \"On Sept. 6, 2020, InSight's weather sensors (collectively called the Auxiliary Payload Sensor Suite, or APSS) were reset. They appear to be operating nominally again, gathering data on wind speed and direction, air temperature and pressure, and magnetic fields. Although the issue that required APSS to be reset has not been determined, the team will continue to carefully monitor the situation.\"}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dictionary to be loaded to flask app\n",
    "\n",
    "mars_dict = {}\n",
    "mars_dict.update(mars_hemi_images)\n",
    "mars_dict['mars_facts_dict']= mars_facts_dict\n",
    "mars_dict['nasa_title'] = nasa_title\n",
    "mars_dict['nasa_paragraph'] = nasa_paragraph\n",
    "mars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
